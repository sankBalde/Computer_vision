{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organic-answer",
   "metadata": {},
   "source": [
    "EPITA 2023 IML lab02_clustering_03-segmentation v2023-03-27_103406 by G. Tochon & J. Chazalon\n",
    "\n",
    "<div style=\"overflow: auto; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"Creative Commons License\" src='img/CC-BY-4.0.png' style='float: left; margin-right: 20px'>\n",
    "    \n",
    "This work is licensed under a [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-blocking",
   "metadata": {},
   "source": [
    "# Lab 2, part 3: Image segmentation using clustering (naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-mortgage",
   "metadata": {},
   "source": [
    "In this part we will apply clustering the segment image into homogeneous regions, as illustrated by the figure below.\n",
    "\n",
    "![](img/segmentation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9e297",
   "metadata": {},
   "source": [
    "This is a naive segmentation version, which is not as elaborated as the [SLIC](https://www.epfl.ch/labs/ivrl/research/slic-superpixels/) approach.\n",
    "However, it illustrates well how to combine color and position information within the same clustering process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-roommate",
   "metadata": {},
   "source": [
    "We put a couple of images from the [Berkeley segmentation dataset](https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/) (BSDS500) under the `data/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-consciousness",
   "metadata": {},
   "source": [
    "The trick is pretty simple here:\n",
    "1. we consider each pixel from the image as points in a 3D color space (RGB);\n",
    "2. we can add some scaled ($\\in [0,1]$) coordinates for each pixel in the image to add spatial information and encourage the clustering to be more consistent with neighbor pixels.\n",
    "\n",
    "We will guide you throughout this first application of clustering for image segmentation.\n",
    "\n",
    "The goal here are to:\n",
    "- try various off-the-shelf clustering algorithms from scikit-learn;\n",
    "- get some intuition about their strengths, weaknesses and use-cases;\n",
    "- learn to generate mesh grids with numpy;\n",
    "- make some nice illustrations;\n",
    "- start to think about computer vision problems like: \n",
    "  - How would you filter the contours generated in the previous figure?\n",
    "  - What would be the problem with using the HSV color space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-makeup",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-playback",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sk\n",
    "import skimage as ski\n",
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-fitting",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to use another image!\n",
    "img = skio.imread(\"data/300091.jpg\")\n",
    "img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-patch",
   "metadata": {},
   "source": [
    "## 1. Simple approach\n",
    "For this first step, we will use color information only. We do not integrate any spatial information in the features (so pixels features = colors).\n",
    "\n",
    "Using a better color space than RGB should be interesting to try too, but let's keep things simple here.\n",
    "Always start with the dumbest possible pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-waste",
   "metadata": {},
   "source": [
    "### 1.1. Predict pixel cluster ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-holocaust",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Using `sklearn.cluster.MiniBatchKMeans`, learn a clustering predictor and predict the cluster ids for each pixel of the image.</b>\n",
    "\n",
    "<b>Hints</b>\n",
    "- Use a low number of clusters (like 6).\n",
    "- Set the `random_state` parameter for reproducibility.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-baseline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's be more serious, use the mini batch version\n",
    "# FIXME\n",
    "# from sklearn.cluster import ???\n",
    "\n",
    "# ...\n",
    "\n",
    "# labels = clusterer.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-harbor",
   "metadata": {},
   "source": [
    "###  1.2. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-rebel",
   "metadata": {},
   "source": [
    "We can now rearrange the labels into a 2D structure of the same width and height as the original image, and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels.reshape(img.shape[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-tennessee",
   "metadata": {},
   "source": [
    "Because colormaps are designed to give similar colors to similar values, the result is not very pleasant to view.\n",
    "\n",
    "What we want is a way to assign very different colors to each cluster of pixels in our image.\n",
    "\n",
    "To do so, we will **build a [lookup table](https://en.wikipedia.org/wiki/Lookup_table) (LUT) to manually assign an adequate color (RGB triplet) to each label value (sequential integers).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "# To learn more about color maps, bookmark this page\n",
    "# https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_lut(n_values):\n",
    "    '''Build a random LUT for `n_values` elements (sequential integers).'''\n",
    "    samples = np.linspace(0, 1, n_values)  # take n_values values between 0 and 1 (evenly spaced)\n",
    "    rng = np.random.default_rng(3)  # get a RNG with a specific seed\n",
    "    samples = rng.permutation(samples)  # shuffle our values\n",
    "    colors = cm.hsv(samples, alpha=None, bytes=True)  # get corresponding colors from the HSV color map\n",
    "    return colors[...,:3]  # remove alpha channel and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random LUT for `n_clusters` elements\n",
    "lut = random_lut(n_clusters)\n",
    "lut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-google",
   "metadata": {},
   "source": [
    "This reads as follows:  \n",
    "(*run next cells!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "_html_data = [\"<ul>\"]\n",
    "for ii, row in enumerate(lut):\n",
    "    _html_data.append(\n",
    "        f\"<li>row <code>{ii}</code>, \"\n",
    "        f\"which will be used of pixels with label <code>{ii}</code>, \" \n",
    "        f\"will get the triplet <code>{tuple(row)}</code>, \"\n",
    "        f\"which correspond to <span style='color: rgb{tuple(row)}'>this color</span></li>\")\n",
    "_html_data.append(\"</ul>\")\n",
    "HTML(\"\".join(_html_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-payday",
   "metadata": {},
   "source": [
    "And now, numpy indexing black magick happens!\n",
    "\n",
    "For each element (integer cluster id) in `labels`, we pick the corresponding color in `lut`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "recolored = lut[labels]\n",
    "recolored.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-evans",
   "metadata": {},
   "source": [
    "We could either reshape `labels` to the shape (row and columns) of the original image, or we can reshape the `recolored` content later, as below.\n",
    "\n",
    "Please feel free to improve this code to your taste!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_seg(img, recolored, n_clusters):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original image\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recolored.reshape(img.shape))\n",
    "    plt.title(f\"Segmented areas (with spatial info), {n_clusters} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_seg(img, recolored, n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-jacob",
   "metadata": {},
   "source": [
    "This is very pretty, but we somehow lack spatial consistency hereâ€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-stamp",
   "metadata": {},
   "source": [
    "## 2. Integrate spatial information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-retail",
   "metadata": {},
   "source": [
    "### 2.1. Data preparation\n",
    "Here you will need to add some spatial information to your pixels to obtain a better spatial consistency in the predictions.\n",
    "\n",
    "Do do so, we will add horizontal and vertical coordinates to each pixel in the image. We will scale these values to have homogeneous features domains (everything in $[0,1]$).\n",
    "\n",
    "First we will create 2 new channels (one with x values and one with y values) for each pixel, then we will create an image with 5 scalars for each pixel: $(R, G, B, X, Y)$, all these values being scaled.\n",
    "\n",
    "Top-left pixel will have the following value: $(R_{00}, G_{00}, B_{00}, 0.0 , 0.0)$ and the bottom right pixel will have the following values: $(R_{HW}, G_{HW}, B_{HW}, 1.0 , 1.0)$ where $H$ (resp. $W$) is the height (resp. width) of the image.\n",
    "\n",
    "**The final image must have the following shape: `(original_img.shape[0], original_img.shape[1], 5)`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-musical",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Using `np.meshgrid`, generate two new channels for the image: one with the x coordinate for each pixel, and one for the y coordinate for each pixel.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-camcorder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "talented-privacy",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Now scale the color values of your image between 0 and 1 to get homogeneous features.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-barrel",
   "metadata": {},
   "source": [
    "Let us scale our image color values between 0 and 1 to facilitate our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_scaled = img / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-alliance",
   "metadata": {},
   "source": [
    "Please note that we can display either uint8 or float pixel values with Matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"data type: {img_scaled.dtype}, min value: {img_scaled.min()}, max value: {img_scaled.max()}\")\n",
    "plt.imshow(img_scaled);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-projection",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Finally, use `np.concatenate` to create the final image. Make sure you check the shape, data type and value domains for the result!</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME\n",
    "# img_sp = ...  # image with SPatial information\n",
    "# img_sp.shape, img_sp.dtype, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-tower",
   "metadata": {},
   "source": [
    "### 2.2. Try `MiniBatchKMeans` again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-mississippi",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Run the same experiment as in section 1: are you happier with the results?</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-administration",
   "metadata": {},
   "source": [
    "Much more object consistency, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-cisco",
   "metadata": {},
   "source": [
    "### 2.3. Try a Gaussian Mixture\n",
    "\n",
    "Let us try again with a more elaborate model.\n",
    "\n",
    "This time we will use a Gaussian Mixture (that we will study further later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-brazilian",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Run the same experiment using `sklearn.mixture.GaussianMixture`, and comment the results. Try various number of clusters.</b>\n",
    "\n",
    "<i>Hint: don't forget to regenerate a LUT if you have a new number of clusters.</i>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-physiology",
   "metadata": {},
   "source": [
    "### 2.4. Try Mean-shift\n",
    "Mean-shift is a kind of non-parametric approach.\n",
    "There is a pretty nice tutorial about it for OpenCV:\n",
    "https://docs.opencv.org/master/d7/d00/tutorial_meanshift.html\n",
    "\n",
    "Scikit-learn also has an implementation at `sklearn.cluster.MeanShift`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-track",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Run the same experiment using `sklearn.cluster.MeanShift`, and comment the results. Use a small bandwith.</b>\n",
    "\n",
    "<i>Hint: Here you do not control the number of clusters but the radius of the ball around which data is considered. As every feature $\\in [0,1]$ we should use a rather small value like $0.2$.</i>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-literacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "steady-reviewer",
   "metadata": {},
   "source": [
    "### 2.5. BIRCH\n",
    "Hey, there are many more clustering technique down here!\n",
    "\n",
    "The illustration of the introduction was generated using BIRCH, but another technique could have been usedâ€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-consensus",
   "metadata": {},
   "source": [
    "<div style=\"overflow: auto; border-style: dotted; border-width: 1px; padding: 10px; margin: 10px 0px\">\n",
    "<img alt=\"work\" src='img/work.png' style='float: left; margin-right: 20px'>\n",
    "\n",
    "<b>Why not trying more classifiers if you have time?</b>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-hardwood",
   "metadata": {},
   "source": [
    "### 2.7. Nice figure\n",
    "\n",
    "As a gift, you can re-generate the beautiful figure from the introduction ðŸ™ƒ!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nice figure to illustrate the introduction of the notebook\n",
    "plt.figure(figsize=(16,11))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(recolored.reshape(img.shape))\n",
    "plt.title(f\"Segmented areas (with spatial info.), {n_clusters} clusters\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(ski.color.rgb2gray(img), cmap='gray')\n",
    "plt.contour(labels.reshape(img.shape[:2]), alpha=0.5, linewidths=1, colors='r')\n",
    "plt.title(\"Contours (red) over original image (gray-level)\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(2,2,4)\n",
    "plt.contour(labels.reshape(img.shape[:2]), \n",
    "            linewidths=0.5, colors='k',\n",
    "            origin='image')\n",
    "plt.title(\"Contours only\")\n",
    "plt.gca().set_aspect(\"equal\")  # works better than # plt.axis(\"equal\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-metabolism",
   "metadata": {},
   "source": [
    "### 2.8. Hierarchical Agglomerative Clustering\n",
    "\n",
    "We have too much data to try a HAC directlyâ€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_clusters = 8\n",
    "# for linkage in ('single', 'average', 'complete', 'ward',):\n",
    "#     clusterer = AgglomerativeClustering(linkage=linkage, n_clusters=n_clusters)\n",
    "#     n_features = 5\n",
    "#     labels = clusterer.fit_predict(img_sp.reshape((-1,n_features)))\n",
    "#     recolored = random_lut(n_clusters)[labels]\n",
    "#     plt.figure(figsize=(12,4))\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(img)\n",
    "#     plt.title(\"Original image\")\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(recolored.reshape(img.shape))\n",
    "#     plt.title(f\"Segmented areas (with spatial info), {n_clusters} clusters, {linkage} linkage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-feeling",
   "metadata": {},
   "source": [
    "MemoryError: Unable to allocate 88.8 GiB for an array with shape (11919757200,) and data type float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-language",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lesser-charleston",
   "metadata": {},
   "source": [
    "# Good job!\n",
    "You are now ready to move on to the next part."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
